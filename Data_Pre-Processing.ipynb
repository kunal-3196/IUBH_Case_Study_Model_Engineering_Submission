{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing : Credit Card Routing for Online Purchase via Predictive Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "**Pandas dataframe** is used for transforming & selecting features through python.\n",
    "Below is the snapshot of the python code & explanation of steps used to derive the cumulative time as an additional feature.\n",
    "\n",
    "The first column tmsp i.e. Original Timestamp provided in the dataset is transformed in a time difference where itâ€™s assumed that the first transaction was initiated at 0 seconds & the next occurred 6 seconds after with the 3rd one occurring 92 seconds after the second & 98 seconds after the 1st transaction. A pattern is followed to consider the time difference obtained as one of the derived features to perform data analysis. Data is prepared using the given excel spreadsheet consisting below details:\n",
    "1.\tTotal transactions(rows): **50470**\n",
    "2.\tTotal features(columns): **7** (Sr. No, timestamp, country, amount, success, PSP, 3D_secured, card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing transformation of timestamp into numeric values of time difference\n",
    "Below code is used to read the provided csv file & store its data into a dataframe called train_data\n",
    "\n",
    "**pd.read_csv**=Used to read a given csv file\n",
    "**pd.DataFrame**=Used to convert a given csv file into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import csv  \n",
    "import datetime as dt\n",
    "#Initiating CSV file\n",
    "csv_file=pd.read_csv(\"C:\\\\MISC\\\\IU_downloads\\\\PSP_Jan_Feb_2019.csv\")\n",
    "#Initiating the dataframe\n",
    "train_data=pd.DataFrame(csv_file,index=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the time difference obtained from the given timestamps in another file\n",
    "This is done by opening the file through **csv writer** & iterating through all the rows thereby selecting the timestamp for each row\n",
    "The timestamps of each subsequent rows are subtracted form one another to obtain a difference in **seconds**. This difference is finally written back to the csv file\n",
    "\n",
    "**datetime.strptime**= Used to convert timestamp in required format\n",
    "**csvwriter.writerow**=Used to write the obtained values one by one in each row of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Providing the timestamp format for conversion of dates\n",
    "format = '%Y-%m-%d %H:%M:%S'\n",
    "#Writing numeric values obtained after converting dates into another csv file\n",
    "with open(\"C:\\\\MISC\\\\IU_downloads\\\\PSP_Jan_Feb_2019_v1.csv\",\"w\") as csvfile:\n",
    "    csvwriter=csv.writer(csvfile)\n",
    "    for i in range(1,len(train_data.axes[0])):\n",
    "          #Converting given timestamp into time difference of seconds starting from 0 seconds with the first record\n",
    "          sec=str((dt.datetime.strptime(train_data[\"tmsp\"][i], format)-dt.datetime.strptime(train_data[\"tmsp\"][i-1], format)).total_seconds())\n",
    "          csvwriter.writerow(sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining transaction fees through python for each transaction\n",
    "This is similar to a vlookup in excel file where both the files can be merged to obtain the transactional fees for every row. In Python it can be done through dataframe as below\n",
    "**pd.merge**= command used to merge two files based on a common column which is \"PSP\" in our case, \n",
    "**pd.concat**= command used to concat two files having same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing paths from local for provided dataset & transaction fees file\n",
    "df_original=pd.DataFrame(pd.read_csv(\"C:\\\\MISC\\\\IU_downloads\\\\PSP_Jan_Feb_2019_original.csv\"),index=None)\n",
    "df_transac_fee=pd.DataFrame(pd.read_csv(\"C:\\\\MISC\\\\IU_downloads\\\\PSP_Jan_Feb_2019_transac_fees.csv\"),index=None)\n",
    "#Extracting only failed transactions from both the files & transforming the dataframe \n",
    "df_original_fail=df_original[df_original[\"success\"]==0]\n",
    "df_transac_fee_fail=df_transac_fee.drop(columns=(\"Success\"))\n",
    "#Merging the two files so that transaction fees are obtained for each failed transaction\n",
    "pd_merge_fail=pd.merge(df_original_fail, df_transac_fee_fail, on=\"PSP\",how=\"inner\")\n",
    "#Extracting only successful transactions from both the files & transforming the dataframe \n",
    "df_original_success=df_original[df_original[\"success\"]==1]\n",
    "df_transac_fee_success=df_transac_fee.drop(columns=(\"Fail\"))\n",
    "#Merging the two files so that transaction fees are obtained for each successful transaction\n",
    "pd_merge_success=pd.merge(df_original_success, df_transac_fee_success, on=\"PSP\",how=\"inner\")\n",
    "#Renaming the column to transaction_fees for each success & failure\n",
    "pd_merge_fail.rename(columns={\"Fail\":\"transaction_fees\"},inplace=True)\n",
    "pd_merge_success.rename(columns={\"Success\":\"transaction_fees\"},inplace=True)\n",
    "#Concatinating & sorting the final file to obtain the required dataset\n",
    "pd_merge_t_fee=pd.concat([pd_merge_fail,pd_merge_success])\n",
    "pd_merge_t_fee_sorted=pd_merge_t_fee.sort_values(by=[\"tmsp\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
